\section{Context free grammars}\label{sec:cfg}
In order to describe the language, a context free grammar is used. A context free grammar (CFG) is a set of recursive rewriting rules, that are used to generate patterns of strings.\\
Michael Sipser describes a CFG as a 4-tuple consisting of (V, $\Sigma$, R, S) where
\begin{itemize}
    \item \textit{V} is a finite set called the \textit{variables}
    \item $\Sigma$ is a finite set, disjoint from \textit{V}, called the terminals
    \item \textit{R} is a finite set of \textit{rules}, with each rule being a variable and a string of variables and terminals
    \item $S \in V$ is the start variable \cite{sipser}.
\end{itemize}

\subsection{BNF and Extended BNF}\label{subsec:bnfEbnf}
In order to formalise the context free grammar, Backus Naur Form (BNF) was created in the late 1950s by John Backus and Peter Naur. This form is used to describe the syntax of the language.\\
BNF uses abstractions for describing the syntactic structures. \\
For example doing an assignment in PHAL such as \textit{Number y := 12} would be given by:
\\\\
<assign> $\xrightarrow{}$ <var> := <expression>
\\\\
The extended version of Backus-Naur Form allows for writing a more compact syntax, using a set of symbols which can be seen on Table~\ref{table:ebnf} \cite{ISOIEC14977}. 

\begin{table}[H]
\centering
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Usage}   & \multicolumn{1}{l}{\textbf{Notation}} \\ \midrule
definition       & =                                     \\
concatenation    & ,                                     \\
termination      & ;                                     \\
alternation      & |                                     \\
optional         & [ \dots ]                             \\
repetition       & \{ \dots \}                           \\
grouping         & ( \dots )                             \\
terminal string  & " \dots "                             \\
terminal string  & ' \dots '                             \\
comment          & (* \dots *)                           \\
special sequence & ? \dots ?                             \\
exception        & -                                     \\\bottomrule
\end{tabular}
\caption{Table of Symbols for EBNF}
\label{table:ebnf}
\end{table}
\noindent
Any grammar defined in EBNF can also be represented in BNF. One of the main differences between BNF and EBNF is that BNF can only represent one rule in a line, whereas EBNF uses a terminating character to mark the end of a rule. In addition to this, EBNF includes mechanisms for defining the number of repetitions, comments etc.
The full EBNF for PHAL can be seen on Appendix~\ref{BFG:BNF}.

\subsection{Parser generator}
In order to create a parser, multiple approaches can be taken. It can either be written by hand, which is both tedious and error prone, or it can be generated using an existing parser generators. In the following part the aspects of the ANTLR4 parser generator will be examined, and LL($k$) grammars will be defined. 

\subsubsection{LL($k$) grammars}
A parsing procedure is associated with each nonterminal, meaning that a derivation must be accomplished through the application of one of the nonterminal's productions. To choose the appropriate production, the parser inspects the next $k$ terminal symbols in the input. This means the choice of production can be predicted on the next $k$ tokens of input, for some constant $k$ chosen before the parser is put to use \cite{CraftinfACompiler}. This is called the lookahead. An example of this could be $k = 1$, meaning the grammar is LL($1$). This means the grammar has productions that can be uniquely predicted for each nonterminal. \textit{LL} means it is a top-down from left to right parser utilising left derivation.\\
The idea of left derivation means that if the parser has multiple possible derivations, it will always choose to expand from the leftmost rule first.\\

\subsubsection{Approach used for PHAL}
As described in Section~\ref{ProblemA:Users}, the language is aimed at users unfamiliar with programming. In accordance with this, we do not expect them to write large programs requiring large amounts of power or efficiency. On top of this, we expect the users to make mistakes during their use of the language, this means error diagnostics should be valued highly in order to give meaningful error messages and help to the user. Based on these considerations, we have decided to implement our parser through a top-down approach as we value better performance and error diagnostics higher than power. We will therefore investigate the different options for LL parser implementation and decide on a final choice.

\subsection{Tools for parser generation}
Parsers and scanners can be generated through different programs. In this section we will discuss JavaCC, Coco/R and ANTLR as tools for generating a scanner and parser for PHAL.

\subsubsection{JavaCC}
\textit{Java Compiler Compiler} or just JavaCC is a parser generator that is implemented in Java. JavaCC is based on LL($k$) grammars and can be used with a variable lookahead which can be set by the user to create a recursive descent parser for a language. 

\subsubsection{Coco/R}
Coco/R is a compiler generator that takes a grammar on EBNF form and generates a scanner and parser for that grammar. The scanner works as a deterministic finite automaton. The parser is a recursive decent parser that can accept languages defined as LL($k$), where $k$ is a constant. There are versions of Coco/R for most modern programming languages such as Java, C\# and C++. 

\subsubsection{ANTLR}\label{ss:antlr}
\textit{Another Tool for Language Recognition}, or simply ANTLR, is a lexer and parser generator written in Java. It accepts a CFG without left recursion and generates an \textit{ALL(*)} parser. The \textit{*} symbol denotes that it uses a variable lookahead. This lookahead is $1$ as often as possible but will vary if needed. The initial \textit{A} in the name means \textit{Adaptive}, and this means grammar analysis is moved to parse-time \cite{AdaptiveLL(*)}.
\\\\
The output of ANTLR is a lexer and parser that uses a \textit{Concrete Syntax Tree} (CST) as its data structure. The CST has more information within its nodes than an \textit{Abstract Syntax Tree} and is thus much larger and may be cumbersome to traverse. Because of this, the CST produced by ANTLR should be converted to an AST to facilitate tree traversal in later phases of the compiler. 

\subsubsection{Choosing a parser generator}
ANTLR was chosen for parser generation for several reasons. 
First and foremost, it allows the usage of EBNF in its configuration file, which in turn makes the grammar more readable, since it is more compact than the regular BNF format. 
\\\\
In addition to the point mentioned in Subsection~\ref{ss:antlr}, ANTLR has a well-developed plugin for Eclipse, which includes intellisense.\\
On top of the perks for the developers, ANTLR allows LL($*$) grammars, which are more powerful than the LL($1$) and LL($k$) parsers.
\\\\
Finally, ANTLR allows the generation of both a parser, lexer and visitor. The visitor generated will be similar to the one described in Section~\ref{comp:ContextualA}.
\\\\
The major downside of using ANTLR is the need to manually convert the created CST to an AST. This downside is mitigated by the other factors described above, and therefore ANTLR was chosen as the tool for parser generation.